"""
Test de IntegraciÃ³n Completa - Proyecto Genesis
Valida todos los componentes del sistema FFE

Componentes testeados:
1. TensorFFE: Estructura fractal 3â†’9â†’27
2. Transcender: SÃ­ntesis emergente no conmutativa
3. Evolver: Aprendizaje de arquetipos, dinÃ¡micas, relatores
4. FFEEncoder: CodificaciÃ³n embeddingâ†’FFE
5. LoRA: AdaptaciÃ³n de LLMs (si PyTorch disponible)
"""

import sys
import numpy as np
from typing import List

# Importar componentes Genesis
from tensor_ffe import (
    TensorFFE, VectorFFE, TransformadorFFE,
    crear_tensor_desde_lista, tensor_nulo
)
from transcender import Transcender, Emergencia
from evolver import Evolver, Arquetipo, Dinamica
from ffe_encoder_mcp import FFEEncoder


def test_tensor_ffe():
    """Test 1: Tensores FFE bÃ¡sicos"""
    print("=" * 60)
    print("TEST 1: Tensores FFE")
    print("=" * 60)
    
    # Crear tensor
    tensor = crear_tensor_desde_lista([3, 5, 7], nivel_abstraccion=3)
    print(f"\nâœ“ Tensor creado: {tensor.nivel_1}")
    print(f"  Nivel abstracciÃ³n: {tensor.nivel_abstraccion}")
    print(f"  Coherencia fractal: {tensor.coherencia():.3f}")
    
    # SerializaciÃ³n
    bits = tensor.to_bits()
    print(f"\nâœ“ SerializaciÃ³n: {len(bits)} bits")
    print(f"  Hex: {hex(int(bits, 2))}")
    
    # DeserializaciÃ³n
    tensor_recuperado = TensorFFE.from_bits(bits)
    match = all(
        v1.forma == v2.forma and v1.funcion == v2.funcion and v1.estructura == v2.estructura
        for v1, v2 in zip(tensor.nivel_1, tensor_recuperado.nivel_1)
    )
    print(f"\nâœ“ DeserializaciÃ³n: {'PASS' if match else 'FAIL'}")
    
    # CompresiÃ³n
    ratio = tensor.compresion_ratio()
    print(f"\nâœ“ Ratio de compresiÃ³n: {ratio:.1f}x")
    print(f"  (117 bits vs {32768} bits tradicionales)")
    
    return tensor


def test_transformador():
    """Test 2: Transformaciones de abstracciÃ³n"""
    print("\n" + "=" * 60)
    print("TEST 2: Transformador FFE (Continuum 0-7)")
    print("=" * 60)
    
    transformador = TransformadorFFE()
    
    # Crear tensor en nivel lÃ©xico (3)
    tensor = crear_tensor_desde_lista([2, 4, 6], nivel_abstraccion=3)
    print(f"\nâœ“ Tensor inicial (nivel 3 - LÃ©xico):")
    print(f"  {tensor.nivel_1}")
    print(f"  Dimensiones activas: {tensor.dimensiones_activas}")
    
    # Abstracting: 3 â†’ 5 (SemÃ¡ntico)
    tensor_abstracto = transformador.abstracting(tensor)
    print(f"\nâœ“ DespuÃ©s de abstracting (nivel {tensor_abstracto.nivel_abstraccion} - SemÃ¡ntico):")
    print(f"  {tensor_abstracto.nivel_1}")
    print(f"  Dimensiones activas: {tensor_abstracto.dimensiones_activas}")
    
    # Extending: 5 â†’ 3 (LÃ©xico)
    tensor_concreto = transformador.extending(tensor_abstracto)
    print(f"\nâœ“ DespuÃ©s de extending (nivel {tensor_concreto.nivel_abstraccion} - LÃ©xico):")
    print(f"  {tensor_concreto.nivel_1}")
    print(f"  Dimensiones activas: {tensor_concreto.dimensiones_activas}")
    
    return tensor


def test_transcender():
    """Test 3: SÃ­ntesis emergente"""
    print("\n" + "=" * 60)
    print("TEST 3: Transcender (SÃ­ntesis Emergente)")
    print("=" * 60)
    
    transcender = Transcender()
    
    # Crear tripleta
    A = crear_tensor_desde_lista([1, 2, 3], 3)
    B = crear_tensor_desde_lista([4, 5, 6], 3)
    C = crear_tensor_desde_lista([7, 0, 1], 4)
    
    print(f"\nâœ“ Entrada:")
    print(f"  A: {A.nivel_1}")
    print(f"  B: {B.nivel_1}")
    print(f"  C: {C.nivel_1}")
    
    # Sintetizar
    emergencia = transcender.sintetizar(A, B, C)
    print(f"\nâœ“ Emergencia generada:")
    print(f"  Score: {emergencia.score_emergencia:.3f}")
    print(f"  Novedad: {emergencia.novedad:.3f}")
    print(f"  Coherencia: {emergencia.coherencia:.3f}")
    print(f"  CompresiÃ³n: {emergencia.compresion:.3f}")
    
    print(f"\nâœ“ Componentes:")
    print(f"  Ms (Structure): {emergencia.Ms.nivel_1}")
    print(f"  Ss (Form): {emergencia.Ss.nivel_1}")
    print(f"  MetaM (Function): {emergencia.MetaM.nivel_1}")
    
    # No conmutatividad
    print(f"\nâœ“ Validando no conmutatividad:")
    resultados = transcender.validar_no_conmutatividad(A, B, C)
    for orden, score in sorted(resultados.items(), key=lambda x: x[1], reverse=True):
        print(f"  {orden}: {score:.4f}")
    
    # Verificar que scores son diferentes
    scores_unicos = len(set(resultados.values()))
    print(f"\n  Scores Ãºnicos: {scores_unicos}/6 {'âœ“ PASS' if scores_unicos > 3 else 'âœ— FAIL'}")
    
    return emergencia


def test_evolver():
    """Test 4: Aprendizaje de patrones"""
    print("\n" + "=" * 60)
    print("TEST 4: Evolver (Aprendizaje Fractal)")
    print("=" * 60)
    
    evolver = Evolver()
    
    # Crear conjunto de tensores similares y diferentes
    tensores = [
        crear_tensor_desde_lista([1, 2, 3], 3),
        crear_tensor_desde_lista([1, 3, 2], 3),  # Similar
        crear_tensor_desde_lista([6, 7, 0], 4),  # Diferente
        crear_tensor_desde_lista([1, 2, 4], 3),  # Similar
        crear_tensor_desde_lista([6, 0, 7], 4),  # Similar al diferente
    ]
    
    print(f"\nâœ“ Aprendiendo {len(tensores)} tensores...")
    
    arquetipos_detectados = set()
    for i, tensor in enumerate(tensores):
        resultado = evolver.aprender(tensor)
        arquetipos_detectados.add(resultado['arquetipo'])
        relaciones = resultado.get('relaciones', [])
        print(f"  Tensor {i+1}: {resultado['arquetipo']} " +
              (f"(+{len(relaciones)} relaciones)" if relaciones else ""))
    
    # EstadÃ­sticas
    stats = evolver.estadisticas()
    print(f"\nâœ“ EstadÃ­sticas finales:")
    print(f"  Arquetipos: {stats['arquetipos']}")
    print(f"  Relatores: {stats['relatores']}")
    print(f"  Conexiones fuertes: {stats['conexiones_fuertes']}")
    
    # Top arquetipos
    print(f"\nâœ“ Top arquetipos por frecuencia:")
    for arq_id, freq in stats['top_arquetipos']:
        print(f"  {arq_id}: {freq} ejemplos")
    
    # Test de dinÃ¡micas
    print(f"\nâœ“ Aprendiendo dinÃ¡mica temporal...")
    secuencia = [
        crear_tensor_desde_lista([0, 0, 0], 2),
        crear_tensor_desde_lista([1, 1, 1], 2),
        crear_tensor_desde_lista([2, 2, 2], 2),
        crear_tensor_desde_lista([3, 3, 3], 2),
    ]
    
    dinamica = evolver.aprender_secuencia(secuencia)
    if dinamica:
        print(f"  DinÃ¡mica {dinamica.id} detectada")
        print(f"  Delta promedio: {dinamica.delta_promedio}")
        
        # Predecir siguiente
        prediccion = dinamica.predecir_siguiente(secuencia[-1])
        print(f"  PredicciÃ³n prÃ³ximo: {prediccion.nivel_1[0]} (esperado: ~(4,4,4))")
    
    return evolver


def test_ffe_encoder():
    """Test 5: CodificaciÃ³n de embeddings"""
    print("\n" + "=" * 60)
    print("TEST 5: FFE Encoder (Embedding â†’ FFE)")
    print("=" * 60)
    
    encoder = FFEEncoder(dimension_embedding=768)
    
    # Generar embedding sintÃ©tico
    embedding = np.random.randn(768).tolist()
    print(f"\nâœ“ Embedding generado: {len(embedding)} dimensiones")
    print(f"  Rango: [{min(embedding):.2f}, {max(embedding):.2f}]")
    
    # Codificar
    tensor = encoder.encode(embedding)
    print(f"\nâœ“ Tensor FFE codificado:")
    print(f"  Nivel 1: {tensor.nivel_1}")
    print(f"  Coherencia: {tensor.coherencia():.3f}")
    
    # Comparar
    comparacion = encoder.compare(embedding, tensor)
    print(f"\nâœ“ ComparaciÃ³n embedding vs FFE:")
    print(f"  Similitud coseno: {comparacion['similitud_coseno']:.3f}")
    print(f"  Error MSE: {comparacion['error_mse']:.4f}")
    print(f"  Ratio compresiÃ³n: {comparacion['ratio_compresion']:.1f}x")
    print(f"  Bits: {comparacion['bits_original']} â†’ {comparacion['bits_ffe']}")
    
    # Decodificar
    reconstruido = encoder.decode(tensor, 768)
    print(f"\nâœ“ Vector reconstruido: {len(reconstruido)} dimensiones")
    print(f"  Rango: [{min(reconstruido):.2f}, {max(reconstruido):.2f}]")
    
    return tensor


def test_lora():
    """Test 6: LoRA (si PyTorch disponible)"""
    print("\n" + "=" * 60)
    print("TEST 6: LoRA FFE (AdaptaciÃ³n de LLMs)")
    print("=" * 60)
    
    try:
        import torch
        from lora_ffe import LoRAConfig, LoRAFFETrainer
        
        print(f"\nâœ“ PyTorch {torch.__version__} detectado")
        
        # ConfiguraciÃ³n
        config = LoRAConfig(rank=8, hidden_dim=768)
        trainer = LoRAFFETrainer(config)
        
        print(f"\nâœ“ LoRA configurado:")
        print(f"  Rank: {config.rank}")
        print(f"  Hidden dim: {config.hidden_dim}")
        print(f"  Alpha: {config.alpha}")
        
        # Generar batch sintÃ©tico
        batch_embeddings = [np.random.randn(768).astype(np.float32) for _ in range(2)]
        batch_targets = [trainer.encoder.encode(emb.tolist()) for emb in batch_embeddings]
        
        print(f"\nâœ“ Batch generado: {len(batch_embeddings)} embeddings")
        
        # Entrenar 1 paso
        print(f"\nâœ“ Entrenando 1 epoch...")
        losses = trainer.train_step(batch_embeddings, batch_targets)
        
        print(f"  Loss total: {losses['total']:.4f}")
        print(f"  l_quant: {losses['sample_0']['l_quant']:.4f}")
        print(f"  l_emerge: {losses['sample_0']['l_emerge']:.4f}")
        
        # Test inferencia
        test_emb = torch.tensor(batch_embeddings[0], dtype=torch.float32)
        vals = trainer.lora1(test_emb)
        _, emergence = trainer.lora2(test_emb)
        
        print(f"\nâœ“ Inferencia LoRAâ‚: {vals.detach().numpy().astype(int)}")
        print(f"âœ“ Inferencia LoRAâ‚‚: emergencia={emergence.item():.3f}")
        
        return True
        
    except ImportError:
        print("\nâš ï¸  PyTorch no instalado")
        print("   Instalar con: pip install torch")
        print("   LoRA disponible pero no ejecutado")
        return False


def test_pipeline_completo():
    """Test 7: Pipeline end-to-end"""
    print("\n" + "=" * 60)
    print("TEST 7: Pipeline Completo Genesis")
    print("=" * 60)
    
    print("\nâœ“ Simulando flujo completo:")
    print("  1. LLM genera embedding")
    print("  2. Encoder convierte a FFE")
    print("  3. Evolver aprende arquetipo")
    print("  4. Transcender sintetiza emergencias")
    print("  5. Transformador navega continuum\n")
    
    # 1. Generar embeddings (3)
    encoder = FFEEncoder(768)
    embeddings = [np.random.randn(768).tolist() for _ in range(3)]
    
    # 2. Codificar a FFE
    tensores = [encoder.encode(emb) for emb in embeddings]
    print(f"âœ“ [1â†’2] Codificados {len(tensores)} embeddings a FFE")
    
    # 3. Aprender arquetipos
    evolver = Evolver()
    for tensor in tensores:
        evolver.aprender(tensor)
    
    stats = evolver.estadisticas()
    print(f"âœ“ [2â†’3] Aprendidos {stats['arquetipos']} arquetipos")
    
    # 4. Sintetizar emergencia
    transcender = Transcender()
    emergencia = transcender.sintetizar(tensores[0], tensores[1], tensores[2])
    print(f"âœ“ [3â†’4] Emergencia sintetizada (score={emergencia.score_emergencia:.3f})")
    
    # 5. Transformar a nivel superior
    transformador = TransformadorFFE()
    tensor_abstracto = transformador.abstracting(emergencia.Ms)
    print(f"âœ“ [4â†’5] Abstracting: nivel {emergencia.Ms.nivel_abstraccion} â†’ {tensor_abstracto.nivel_abstraccion}")
    
    print(f"\nâœ“ Pipeline completado exitosamente!")
    print(f"  Input: {len(embeddings)} embeddings Ã— {len(embeddings[0])} dims")
    print(f"  Output: Emergencia nivel {tensor_abstracto.nivel_abstraccion} (117 bits)")
    print(f"  CompresiÃ³n total: ~{(len(embeddings) * 768 * 32) / 117:.0f}x")


def main():
    """Ejecuta todos los tests"""
    print("\n" + "ğŸŒŒ" * 30)
    print(" " * 20 + "PROYECTO GENESIS")
    print(" " * 15 + "Test de IntegraciÃ³n Completa")
    print("ğŸŒŒ" * 30 + "\n")
    
    tests_passed = 0
    tests_total = 7
    
    try:
        test_tensor_ffe()
        tests_passed += 1
    except Exception as e:
        print(f"\nâœ— TEST 1 FAILED: {e}")
    
    try:
        test_transformador()
        tests_passed += 1
    except Exception as e:
        print(f"\nâœ— TEST 2 FAILED: {e}")
    
    try:
        test_transcender()
        tests_passed += 1
    except Exception as e:
        print(f"\nâœ— TEST 3 FAILED: {e}")
    
    try:
        test_evolver()
        tests_passed += 1
    except Exception as e:
        print(f"\nâœ— TEST 4 FAILED: {e}")
    
    try:
        test_ffe_encoder()
        tests_passed += 1
    except Exception as e:
        print(f"\nâœ— TEST 5 FAILED: {e}")
    
    try:
        lora_ok = test_lora()
        if lora_ok:
            tests_passed += 1
        else:
            tests_passed += 0.5  # Medio punto si no hay PyTorch
    except Exception as e:
        print(f"\nâœ— TEST 6 FAILED: {e}")
    
    try:
        test_pipeline_completo()
        tests_passed += 1
    except Exception as e:
        print(f"\nâœ— TEST 7 FAILED: {e}")
    
    # Resumen final
    print("\n" + "=" * 60)
    print("RESUMEN DE TESTS")
    print("=" * 60)
    print(f"\nâœ“ Tests pasados: {tests_passed}/{tests_total}")
    
    if tests_passed == tests_total:
        print("\nğŸ‰ Â¡PROYECTO GENESIS COMPLETAMENTE OPERACIONAL! ğŸ‰")
    elif tests_passed >= tests_total - 1:
        print("\nâœ… Sistema operacional (algunos componentes opcionales faltantes)")
    else:
        print("\nâš ï¸  Algunos componentes requieren atenciÃ³n")
    
    print("\n" + "ğŸŒŒ" * 30 + "\n")


if __name__ == "__main__":
    main()
